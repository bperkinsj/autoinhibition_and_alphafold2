{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook for calculating the Shannon Entropy of my multiple sequence alignments. Adapted from Joe Healey's Shannon.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import project_pipeline.scripts.utils as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Joe R. J. Healey\"\n",
    "__version__ = \"1.0.0\"\n",
    "__title__ = \"ShannonMSA\"\n",
    "__license__ = \"GPLv3\"\n",
    "__author_email__ = \"J.R.J.Healey@warwick.ac.uk\"\n",
    "\n",
    "def parseMSA(msa, alnformat, verbose):\n",
    "    \"\"\"Parse in the MSA file using Biopython's AlignIO\"\"\"\n",
    "\n",
    "    alignment = AlignIO.read(msa, alnformat)\n",
    "\n",
    "    # Do a little sanity checking:\n",
    "    seq_lengths_list = []\n",
    "    n_seqs = len(alignment._records)\n",
    "    for record in alignment:\n",
    "       seq_lengths_list.append(len(record))\n",
    "\n",
    "    seq_lengths = set(seq_lengths_list)\n",
    "\n",
    "    if verbose > 0: print(\"Alignment length is:\" + str(list(seq_lengths)))\n",
    "\n",
    "    if len(seq_lengths) != 1:\n",
    "        sys.stderr.write(\"Your alignment lengths aren't equal. Check your alignment file.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    index = range(1, list(seq_lengths)[0]+1)\n",
    "\n",
    "    return alignment, list(seq_lengths), index, n_seqs\n",
    "\n",
    "##################################################################\n",
    "# Function to calcuate the Shannon's entropy per alignment column\n",
    "# H=-\\sum_{i=1}^{M} P_i\\,log_2\\,P_i (http://imed.med.ucm.es/Tools/svs_help.html)\n",
    "# Gaps and N's are included in the calculation\n",
    "##################################################################\n",
    "\n",
    "def shannon_entropy(list_input):\n",
    "    \"\"\"Calculate Shannon's Entropy per column of the alignment (H=-\\sum_{i=1}^{M} P_i\\,log_2\\,P_i)\"\"\"\n",
    "\n",
    "    import math\n",
    "    unique_base = set(list_input)\n",
    "    M   =  len(list_input)\n",
    "    entropy_list = []\n",
    "    # Number of residues in column\n",
    "    for base in unique_base:\n",
    "        n_i = list_input.count(base) # Number of residues of type i\n",
    "        P_i = n_i/float(M) # n_i(Number of residues of type i) / M(Number of residues in column)\n",
    "        entropy_i = P_i*(math.log(P_i,2))\n",
    "        entropy_list.append(entropy_i)\n",
    "\n",
    "    sh_entropy = -(sum(entropy_list))\n",
    "\n",
    "    return sh_entropy\n",
    "\n",
    "\n",
    "def shannon_entropy_list_msa(alignment):\n",
    "    \"\"\"Calculate Shannon Entropy across the whole MSA\"\"\"\n",
    "\n",
    "    shannon_entropy_list = []\n",
    "    for col_no in range(len(list(alignment[0]))):\n",
    "        list_input = list(alignment[:, col_no])\n",
    "        shannon_entropy_list.append(shannon_entropy(list_input))\n",
    "\n",
    "    return shannon_entropy_list\n",
    "\n",
    "def plot(index, sel, verbose):\n",
    "    \"\"\"\"Create a quick plot via matplotlib to visualise\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if verbose > 0: print(\"Plotting data...\")\n",
    "\n",
    "    plt.plot(index, sel)\n",
    "    plt.xlabel('MSA Position Index', fontsize=16)\n",
    "    plt.ylabel('Shannon Entropy', fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def running_mean(l, N):\n",
    "    sum = 0\n",
    "    result = list(0 for x in l)\n",
    "\n",
    "    for i in range( 0, N ):\n",
    "        sum = sum + l[i]\n",
    "        result[i] = sum / (i+1)\n",
    "\n",
    "    for i in range( N, len(l) ):\n",
    "        sum = sum - l[i-N] + l[i]\n",
    "        result[i] = sum / N\n",
    "\n",
    "    return result\n",
    "\n",
    "def region_shannon(array):\n",
    "    '''\n",
    "    Determine average shannon entropy and percentage of high-variable columns\n",
    "    for a given sequence array\n",
    "    '''\n",
    "\n",
    "    reg_mean = np.mean(array)\n",
    "    reg_n_high = len(array[array >= 2.0])\n",
    "    reg_n = len(array)\n",
    "    perc_n_high = reg_n_high / reg_n\n",
    "\n",
    "    return [reg_n, reg_n_high, perc_n_high, reg_mean]\n",
    "\n",
    "\n",
    "def compute_shannon(msa, reg1, reg2, alnformat='fasta', verbose=0):\n",
    "\n",
    "    alignment, seq_lengths, index, nseq = parseMSA(msa, alnformat, verbose)\n",
    "    sel = np.array(shannon_entropy_list_msa(alignment))\n",
    "\n",
    "    prefixes = ['w_', 'reg1_', 'reg2_', 'both_reg_', 'o_reg_']\n",
    "    suffixes = ['n', 'nh', 'perc_h', 'mean']\n",
    "    keys = ['nseq'] # Start with number of sequences\n",
    "    for p in prefixes:\n",
    "        for s in suffixes:\n",
    "            keys.append(p + s)\n",
    "\n",
    "    values = [nseq] # Start with number of sequences\n",
    "\n",
    "    # Statistics for entire array\n",
    "    values = values + region_shannon(sel)\n",
    "\n",
    "    # Statistics for regions 1 and 2\n",
    "    # One of my proteins has the incorrect upper bound, so we will have to make an exception for that\n",
    "    try:\n",
    "        values = values + region_shannon(np.take(sel, reg1))\n",
    "    except IndexError:\n",
    "        reg1 = reg1[:-1]\n",
    "        values = values + region_shannon(np.take(sel, reg1))\n",
    "    values = values + region_shannon(np.take(sel, reg2))\n",
    "\n",
    "    # Statistics for both regions\n",
    "    values = values + region_shannon(np.take(sel, reg1 + reg2))\n",
    "\n",
    "    # Statistics for all other regions\n",
    "    sub_array = np.delete(sel, reg1 + reg2)\n",
    "    values = values + region_shannon(sub_array)\n",
    "\n",
    "    temp_dic = {k: v for k, v in zip(keys, values)}\n",
    "\n",
    "    return temp_dic\n",
    "\n",
    "\n",
    "def main(df, path):\n",
    "    '''\n",
    "    Collect Shannon entropy info for each msa in our dataset. For a summary statistic, we will count the number\n",
    "    of indices with H >= 2.0. We will also collect information on how many sequences there are.\n",
    "    '''\n",
    "    shan_df = pd.DataFrame()\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        unp = row['uniprot']\n",
    "        clst = row['cluster']\n",
    "        reg1 = utils.string2range(row['region_1'])\n",
    "        reg2 = utils.string2range(row['region_2'])\n",
    "\n",
    "        # Adjust regions to serve as indices\n",
    "        reg1 = [x - 1 for x in reg1]\n",
    "        reg2 = [x - 1 for x in reg2]\n",
    "\n",
    "        # Open the cluster file to get the UniRef IDs\n",
    "        fn = f'{unp}_{clst}.a3m'\n",
    "        fp = os.path.join(path, unp, fn) # File path looks like data/O08967/O08967_000.a3m\n",
    "        temp_dic = compute_shannon(fp, reg1, reg2)\n",
    "\n",
    "        temp_df = pd.DataFrame([{'uniprot': unp, 'cluster': clst, **temp_dic}])\n",
    "\n",
    "        shan_df = pd.concat([shan_df, temp_df]).reset_index(drop=True)\n",
    "\n",
    "    return shan_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot</th>\n",
       "      <th>cluster</th>\n",
       "      <th>nseq</th>\n",
       "      <th>w_n</th>\n",
       "      <th>w_nh</th>\n",
       "      <th>w_perc_h</th>\n",
       "      <th>w_mean</th>\n",
       "      <th>reg1_n</th>\n",
       "      <th>reg1_nh</th>\n",
       "      <th>reg1_perc_h</th>\n",
       "      <th>...</th>\n",
       "      <th>reg2_perc_h</th>\n",
       "      <th>reg2_mean</th>\n",
       "      <th>both_reg_n</th>\n",
       "      <th>both_reg_nh</th>\n",
       "      <th>both_reg_perc_h</th>\n",
       "      <th>both_reg_mean</th>\n",
       "      <th>o_reg_n</th>\n",
       "      <th>o_reg_nh</th>\n",
       "      <th>o_reg_perc_h</th>\n",
       "      <th>o_reg_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P07038</td>\n",
       "      <td>U10-003</td>\n",
       "      <td>11</td>\n",
       "      <td>920</td>\n",
       "      <td>392</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>1.629037</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>1.882610</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.465711</td>\n",
       "      <td>830</td>\n",
       "      <td>357</td>\n",
       "      <td>0.430120</td>\n",
       "      <td>1.646747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P07038</td>\n",
       "      <td>000</td>\n",
       "      <td>4</td>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093473</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117185</td>\n",
       "      <td>830</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P07038</td>\n",
       "      <td>U10-007</td>\n",
       "      <td>11</td>\n",
       "      <td>920</td>\n",
       "      <td>359</td>\n",
       "      <td>0.390217</td>\n",
       "      <td>1.583648</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.834187</td>\n",
       "      <td>90</td>\n",
       "      <td>32</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>1.581026</td>\n",
       "      <td>830</td>\n",
       "      <td>327</td>\n",
       "      <td>0.393976</td>\n",
       "      <td>1.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P07038</td>\n",
       "      <td>U10-008</td>\n",
       "      <td>11</td>\n",
       "      <td>920</td>\n",
       "      <td>432</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>1.705492</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>2.000250</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>1.600153</td>\n",
       "      <td>830</td>\n",
       "      <td>391</td>\n",
       "      <td>0.471084</td>\n",
       "      <td>1.716914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P07038</td>\n",
       "      <td>U100-005</td>\n",
       "      <td>101</td>\n",
       "      <td>920</td>\n",
       "      <td>528</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>2.091565</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>2.542571</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.020354</td>\n",
       "      <td>830</td>\n",
       "      <td>483</td>\n",
       "      <td>0.581928</td>\n",
       "      <td>2.099287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot   cluster  nseq  w_n  w_nh  w_perc_h    w_mean  reg1_n  reg1_nh  \\\n",
       "0  P07038   U10-003    11  920   392  0.426087  1.629037      26        0   \n",
       "1  P07038       000     4  920     0  0.000000  0.093473      26        0   \n",
       "2  P07038   U10-007    11  920   359  0.390217  1.583648      26        0   \n",
       "3  P07038   U10-008    11  920   432  0.469565  1.705492      26        0   \n",
       "4  P07038  U100-005   101  920   528  0.573913  2.091565      26        0   \n",
       "\n",
       "   reg1_perc_h  ...  reg2_perc_h  reg2_mean  both_reg_n  both_reg_nh  \\\n",
       "0          0.0  ...     0.546875   1.882610          90           35   \n",
       "1          0.0  ...     0.000000   0.012676          90            0   \n",
       "2          0.0  ...     0.500000   1.834187          90           32   \n",
       "3          0.0  ...     0.640625   2.000250          90           41   \n",
       "4          0.0  ...     0.703125   2.542571          90           45   \n",
       "\n",
       "   both_reg_perc_h  both_reg_mean  o_reg_n  o_reg_nh  o_reg_perc_h  o_reg_mean  \n",
       "0         0.388889       1.465711      830       357      0.430120    1.646747  \n",
       "1         0.000000       0.117185      830         0      0.000000    0.090902  \n",
       "2         0.355556       1.581026      830       327      0.393976    1.583932  \n",
       "3         0.455556       1.600153      830       391      0.471084    1.716914  \n",
       "4         0.500000       2.020354      830       483      0.581928    2.099287  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Autoinhibitory\n",
    "df = pd.read_csv('./project_pipeline/data/ai_pdb_clusters.tsv', sep='\\t')[['uniprot', 'cluster', 'region_1', 'region_2']].drop_duplicates().reset_index(drop=True)\n",
    "path = './autoinhibition_clusters/'\n",
    "\n",
    "shan_df = main(df, path)\n",
    "shan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot</th>\n",
       "      <th>cluster</th>\n",
       "      <th>nseq</th>\n",
       "      <th>w_n</th>\n",
       "      <th>w_nh</th>\n",
       "      <th>w_perc_h</th>\n",
       "      <th>w_mean</th>\n",
       "      <th>reg1_n</th>\n",
       "      <th>reg1_nh</th>\n",
       "      <th>reg1_perc_h</th>\n",
       "      <th>...</th>\n",
       "      <th>reg2_perc_h</th>\n",
       "      <th>reg2_mean</th>\n",
       "      <th>both_reg_n</th>\n",
       "      <th>both_reg_nh</th>\n",
       "      <th>both_reg_perc_h</th>\n",
       "      <th>both_reg_mean</th>\n",
       "      <th>o_reg_n</th>\n",
       "      <th>o_reg_nh</th>\n",
       "      <th>o_reg_perc_h</th>\n",
       "      <th>o_reg_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D9N168</td>\n",
       "      <td>U10-007</td>\n",
       "      <td>11</td>\n",
       "      <td>579</td>\n",
       "      <td>238</td>\n",
       "      <td>0.411054</td>\n",
       "      <td>1.615098</td>\n",
       "      <td>167</td>\n",
       "      <td>95</td>\n",
       "      <td>0.568862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331731</td>\n",
       "      <td>1.401645</td>\n",
       "      <td>375</td>\n",
       "      <td>164</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>1.686246</td>\n",
       "      <td>204</td>\n",
       "      <td>74</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>1.484311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D9N168</td>\n",
       "      <td>U100-004</td>\n",
       "      <td>101</td>\n",
       "      <td>579</td>\n",
       "      <td>342</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>2.132564</td>\n",
       "      <td>167</td>\n",
       "      <td>130</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.856641</td>\n",
       "      <td>375</td>\n",
       "      <td>230</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>2.191116</td>\n",
       "      <td>204</td>\n",
       "      <td>112</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>2.024932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D9N168</td>\n",
       "      <td>U10-005</td>\n",
       "      <td>11</td>\n",
       "      <td>579</td>\n",
       "      <td>263</td>\n",
       "      <td>0.454231</td>\n",
       "      <td>1.648029</td>\n",
       "      <td>167</td>\n",
       "      <td>106</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350962</td>\n",
       "      <td>1.447240</td>\n",
       "      <td>375</td>\n",
       "      <td>179</td>\n",
       "      <td>0.477333</td>\n",
       "      <td>1.707169</td>\n",
       "      <td>204</td>\n",
       "      <td>84</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>1.539315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D9N168</td>\n",
       "      <td>U100-002</td>\n",
       "      <td>101</td>\n",
       "      <td>579</td>\n",
       "      <td>364</td>\n",
       "      <td>0.628670</td>\n",
       "      <td>2.243077</td>\n",
       "      <td>167</td>\n",
       "      <td>139</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>1.939129</td>\n",
       "      <td>375</td>\n",
       "      <td>244</td>\n",
       "      <td>0.650667</td>\n",
       "      <td>2.315004</td>\n",
       "      <td>204</td>\n",
       "      <td>120</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>2.110859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D9N168</td>\n",
       "      <td>U10-009</td>\n",
       "      <td>11</td>\n",
       "      <td>579</td>\n",
       "      <td>264</td>\n",
       "      <td>0.455959</td>\n",
       "      <td>1.684303</td>\n",
       "      <td>167</td>\n",
       "      <td>112</td>\n",
       "      <td>0.670659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360577</td>\n",
       "      <td>1.434128</td>\n",
       "      <td>375</td>\n",
       "      <td>187</td>\n",
       "      <td>0.498667</td>\n",
       "      <td>1.751471</td>\n",
       "      <td>204</td>\n",
       "      <td>77</td>\n",
       "      <td>0.377451</td>\n",
       "      <td>1.560832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot   cluster  nseq  w_n  w_nh  w_perc_h    w_mean  reg1_n  reg1_nh  \\\n",
       "0  D9N168   U10-007    11  579   238  0.411054  1.615098     167       95   \n",
       "1  D9N168  U100-004   101  579   342  0.590674  2.132564     167      130   \n",
       "2  D9N168   U10-005    11  579   263  0.454231  1.648029     167      106   \n",
       "3  D9N168  U100-002   101  579   364  0.628670  2.243077     167      139   \n",
       "4  D9N168   U10-009    11  579   264  0.455959  1.684303     167      112   \n",
       "\n",
       "   reg1_perc_h  ...  reg2_perc_h  reg2_mean  both_reg_n  both_reg_nh  \\\n",
       "0     0.568862  ...     0.331731   1.401645         375          164   \n",
       "1     0.778443  ...     0.480769   1.856641         375          230   \n",
       "2     0.634731  ...     0.350962   1.447240         375          179   \n",
       "3     0.832335  ...     0.504808   1.939129         375          244   \n",
       "4     0.670659  ...     0.360577   1.434128         375          187   \n",
       "\n",
       "   both_reg_perc_h  both_reg_mean  o_reg_n  o_reg_nh  o_reg_perc_h  o_reg_mean  \n",
       "0         0.437333       1.686246      204        74      0.362745    1.484311  \n",
       "1         0.613333       2.191116      204       112      0.549020    2.024932  \n",
       "2         0.477333       1.707169      204        84      0.411765    1.539315  \n",
       "3         0.650667       2.315004      204       120      0.588235    2.110859  \n",
       "4         0.498667       1.751471      204        77      0.377451    1.560832  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two-domain\n",
    "md = pd.read_csv('./project_pipeline/data/md_pdb_clusters.tsv', sep='\\t')[['uniprot', 'cluster', 'region_1', 'region_2']].drop_duplicates().reset_index(drop=True)\n",
    "path2 = './multi_domain_clusters'\n",
    "\n",
    "shan_md = main(md, path2)\n",
    "shan_md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "shan_df.to_csv('./project_pipeline/data/ai_af2_clusters_shannon_entropy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shan_md.to_csv('./project_pipeline/data/md_af2_clusters_shannon_entropy.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmsd_snek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
